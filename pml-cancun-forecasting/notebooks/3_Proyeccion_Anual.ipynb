{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befe27f6",
   "metadata": {},
   "source": [
    "# Proyecci√≥n Anual del PML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo cargado correctamente\n",
      "üìä Dimensiones: (17470, 6)\n",
      "            fecha  hora    zona  precio  energia  congestion\n",
      "17465  30/09/2020    20  CANCUN  604.48   523.48         0.0\n",
      "17466  30/09/2020    21  CANCUN  620.15   531.40         0.0\n",
      "17467  30/09/2020    22  CANCUN  625.37   532.39         0.0\n",
      "17468  30/09/2020    23  CANCUN  625.96   521.96         0.0\n",
      "17469  30/09/2020    24  CANCUN  625.87   519.85         0.0\n",
      "‚úÖ Todas las fechas convertidas exitosamente\n",
      "\n",
      "Ejemplo de fechas convertidas:\n",
      "       fecha  hora          fecha_hora\n",
      "0 2020-04-01     1 2020-04-01 00:00:00\n",
      "1 2020-04-01     2 2020-04-01 01:00:00\n",
      "2 2020-04-01     3 2020-04-01 02:00:00\n",
      "\n",
      "Ejemplo del registro problem√°tico convertido:\n",
      "          fecha  hora    zona   precio  energia  congestion  \\\n",
      "6093 2024-08-15     1  CANCUN  5770.44  1082.40     4418.25   \n",
      "6094 2024-08-15     2  CANCUN   970.89   774.01       -0.12   \n",
      "6095 2024-08-15     3  CANCUN   634.29   508.03       -0.25   \n",
      "6096 2024-08-15     4  CANCUN   544.40   440.25       -0.19   \n",
      "6097 2024-08-15     5  CANCUN   511.91   422.06       -0.14   \n",
      "\n",
      "              fecha_hora  \n",
      "6093 2024-08-15 00:00:00  \n",
      "6094 2024-08-15 01:00:00  \n",
      "6095 2024-08-15 02:00:00  \n",
      "6096 2024-08-15 03:00:00  \n",
      "6097 2024-08-15 04:00:00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "ruta = 'C:/Cursos/Data Science/Proyecto CENANCE/pml-cancun-forecasting/data/PML_CANCUN_FINAL.csv'\n",
    "\n",
    "# Cargar Datos\n",
    "try:\n",
    "    df = pd.read_csv(ruta, parse_dates=['fecha'])\n",
    "    print(\"‚úÖ Archivo cargado correctamente\")\n",
    "    print(f\"üìä Dimensiones: {df.shape}\")\n",
    "    \n",
    "    # Mostrar las primeras filas \n",
    "    print(df.tail())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el archivo: {str(e)}\")\n",
    "    print(\"\\nüîç Verifica:\")\n",
    "    print(f\"1. Que el archivo existe en: {ruta}\")\n",
    "    print(\"2. Que el nombre del archivo es exactamente 'PML_CANCUN_FINAL.csv'\")\n",
    "    print(\"3. Que no hay caracteres especiales en la ruta\")\n",
    "    \n",
    "def parse_mixed_dates(date_str):\n",
    "    try:\n",
    "        # Primero intenta con formato AAAA-MM-DD\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Si falla, intenta con formato DD/MM/AAAA\n",
    "            return pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            # Si ambos fallan, devuelve NaT (Not a Time)\n",
    "            return pd.NaT\n",
    "\n",
    "# Aplicar la funci√≥n a la columna de fechas\n",
    "df['fecha'] = df['fecha'].apply(parse_mixed_dates)\n",
    "\n",
    "# Verificar si hay fechas no convertidas\n",
    "if df['fecha'].isna().any():\n",
    "    print(f\"‚ö†Ô∏è Advertencia: {df['fecha'].isna().sum()} fechas no pudieron convertirse\")\n",
    "    print(\"Registros problem√°ticos:\")\n",
    "    print(df[df['fecha'].isna()])\n",
    "else:\n",
    "    print(\"‚úÖ Todas las fechas convertidas exitosamente\")\n",
    "\n",
    "# Combinar con la hora (1-24) para crear timestamp completo\n",
    "df['fecha_hora'] = df['fecha'] + pd.to_timedelta(df['hora'] - 1, unit='h')\n",
    "\n",
    "# Eliminar filas con fechas inv√°lidas si es necesario\n",
    "df = df.dropna(subset=['fecha'])\n",
    "\n",
    "# Verificar resultados\n",
    "print(\"\\nEjemplo de fechas convertidas:\")\n",
    "print(df[['fecha', 'hora', 'fecha_hora']].head(3))\n",
    "print(\"\\nEjemplo del registro problem√°tico convertido:\")\n",
    "print(df[df['fecha_hora'].dt.strftime('%d/%m/%Y') == '15/08/2024'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73288f19",
   "metadata": {},
   "source": [
    "# --------------------------\n",
    "# 1. Escenarios y supuestos a largo plazo\n",
    "\n",
    "Para la proyecci√≥n anual del Precio Marginal Local (PML), se consideran los siguientes supuestos:\n",
    "\n",
    "- Se mantiene el comportamiento estacional observado en los datos hist√≥ricos.\n",
    "- No se contemplan eventos extraordinarios como cambios regulatorios, desastres naturales o crisis econ√≥micas.\n",
    "- Se espera una demanda energ√©tica relativamente estable, sin incrementos abruptos ni decrecimientos marcados.\n",
    "- Los modelos se entrenan √∫nicamente con series hist√≥ricas de precios, sin variables ex√≥genas.\n",
    "- Las proyecciones a 1, 3 y 5 a√±os se hacen con frecuencias horarias y agregaciones anuales posteriores para facilitar el an√°lisis.\n",
    "\n",
    "Estos supuestos permiten generar escenarios base √∫tiles para an√°lisis exploratorios y planeaci√≥n energ√©tica.\n",
    "\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cb8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados y preprocesados exitosamente.\n",
      "üìä Dimensiones despu√©s de limpieza: (51959, 1)\n",
      "\n",
      "üîç Primeras filas:\n",
      "                      precio\n",
      "fecha_hora                 \n",
      "2020-01-01 01:00:00  428.23\n",
      "2020-01-01 02:00:00  396.10\n",
      "2020-01-01 03:00:00  374.27\n",
      "2020-01-01 04:00:00  359.29\n",
      "2020-01-01 05:00:00  327.40\n",
      "\n",
      "‚öôÔ∏è Buscando par√°metros √≥ptimos para SARIMA...\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(1,0,1)[24] intercept   : AIC=798554.260, Time=394.69 sec\n",
      " ARIMA(0,1,0)(0,0,0)[24] intercept   : AIC=799643.194, Time=0.73 sec\n",
      " ARIMA(1,1,0)(1,0,0)[24] intercept   : AIC=798954.676, Time=65.87 sec\n",
      " ARIMA(0,1,1)(0,0,1)[24] intercept   : AIC=798854.826, Time=88.16 sec\n",
      " ARIMA(0,1,0)(0,0,0)[24]             : AIC=799641.194, Time=0.39 sec\n",
      " ARIMA(2,1,2)(0,0,1)[24] intercept   : AIC=798552.260, Time=373.51 sec\n",
      " ARIMA(2,1,2)(0,0,0)[24] intercept   : AIC=798550.339, Time=7.14 sec\n",
      "\n",
      "‚ùå ERROR CR√çTICO en el modelado o pron√≥stico: Unable to allocate 21.4 MiB for an array with shape (27, 51959) and data type complex128\n",
      "Por favor, revisa los pasos anteriores y aseg√∫rate de que los datos est√©n correctamente cargados y preprocesados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ruta = 'C:/Cursos/Data Science/Proyecto CENANCE/pml-cancun-forecasting/data/PML_CANCUN_FINAL.csv'\n",
    "\n",
    "# 1. Cargar datos de manera ROBUSTA\n",
    "try:\n",
    "    df = pd.read_csv(ruta)\n",
    "    # Intentamos combinar las columnas 'fecha' y 'hora' directamente al cargar\n",
    "    df['fecha_hora'] = pd.to_datetime(df['fecha'] + ' ' + df['hora'].astype(str) + ':00', errors='coerce')\n",
    "    df = df.dropna(subset=['fecha_hora', 'precio']) # Eliminar filas donde no se pudo crear la fecha o no hay precio\n",
    "    df['precio'] = pd.to_numeric(df['precio'], errors='coerce') # Asegurar que el precio sea num√©rico\n",
    "    df = df.dropna(subset=['precio'])\n",
    "    df = df[['fecha_hora', 'precio']].sort_values(by='fecha_hora').drop_duplicates(subset=['fecha_hora'], keep='first').set_index('fecha_hora')\n",
    "    df = df.asfreq('H', method='ffill') # Forzar frecuencia horaria llenando huecos con el √∫ltimo valor v√°lido\n",
    "\n",
    "    print(\"‚úÖ Datos cargados y preprocesados exitosamente.\")\n",
    "    print(f\"üìä Dimensiones despu√©s de limpieza: {df.shape}\")\n",
    "    print(\"\\nüîç Primeras filas:\\n\", df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: El archivo no se encontr√≥ en la ruta: {ruta}\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Error: No se encontraron las columnas esperadas ({e}). Verifica el nombre de las columnas en tu CSV.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inesperado al cargar y preprocesar los datos: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Modelado SARIMA con b√∫squeda autom√°tica de par√°metros\n",
    "try:\n",
    "    print(\"\\n‚öôÔ∏è Buscando par√°metros √≥ptimos para SARIMA...\")\n",
    "    modelo_auto = auto_arima(\n",
    "    df['precio'],\n",
    "    seasonal=True,\n",
    "    m=24,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    trace=True,\n",
    "    error_action='ignore',\n",
    "    max_p=2, \n",
    "    max_q=2, \n",
    "    max_P=1, \n",
    "    max_Q=1  \n",
    ")\n",
    "    print(\"\\n‚úÖ Par√°metros √≥ptimos encontrados:\")\n",
    "    print(modelo_auto.summary())\n",
    "\n",
    "    # 3. Entrenar el modelo SARIMAX con los par√°metros encontrados\n",
    "    order = modelo_auto.order\n",
    "    seasonal_order = modelo_auto.seasonal_order\n",
    "\n",
    "    modelo_sarima = SARIMAX(df['precio'],\n",
    "                            order=order,\n",
    "                            seasonal_order=seasonal_order,\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False)\n",
    "    resultado = modelo_sarima.fit(disp=False)\n",
    "    print(\"\\n‚úÖ Modelo SARIMAX entrenado.\")\n",
    "\n",
    "    # 4. Generar pron√≥sticos\n",
    "    horas_pronostico = {\n",
    "        '1 a√±o': 24 * 365,\n",
    "        '3 a√±os': 24 * 365 * 3,\n",
    "        '5 a√±os': 24 * 365 * 5\n",
    "    }\n",
    "    predicciones_sarima = {}\n",
    "\n",
    "    for label, h in horas_pronostico.items():\n",
    "        pred = resultado.get_forecast(steps=h)\n",
    "        pred_df = pd.DataFrame({'precio_predicho': pred.predicted_mean})\n",
    "        pred_df.index = pd.date_range(start=df.index[-1], periods=h, freq='H')\n",
    "        predicciones_sarima[label] = pred_df.reset_index().rename(columns={'index': 'fecha_hora'})\n",
    "        print(f\"\\n‚úÖ Pron√≥stico para {label} generado.\")\n",
    "\n",
    "    # 5. Visualizaci√≥n\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df[-24 * 30:], label='Hist√≥rico (√∫ltimos 30 d√≠as)')\n",
    "    for label, df_pred in predicciones_sarima.items():\n",
    "        plt.plot(df_pred['fecha_hora'], df_pred['precio_predicho'], label=f'Proyecci√≥n {label}')\n",
    "    plt.legend()\n",
    "    plt.title(\"Proyecciones SARIMA a 1, 3 y 5 a√±os\")\n",
    "    plt.xlabel(\"Fecha\")\n",
    "    plt.ylabel(\"Precio\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 6. Exportar a CSV\n",
    "    for label, df_pred in predicciones_sarima.items():\n",
    "        archivo = f\"proyeccion_sarima_{label.replace(' ', '_')}.csv\"\n",
    "        df_pred.to_csv(archivo, index=False)\n",
    "        print(f\"üì§ Archivo exportado: {archivo}\")\n",
    "\n",
    "    print(\"\\nüéâ ¬°Proceso de proyecci√≥n anual completado con √©xito!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR CR√çTICO en el modelado o pron√≥stico: {e}\")\n",
    "    print(\"Por favor, revisa los pasos anteriores y aseg√∫rate de que los datos est√©n correctamente cargados y preprocesados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912fa4ac",
   "metadata": {},
   "source": [
    "# --------------------------\n",
    "# 2. Modelo Prophet (log)\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddeef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df.copy()\n",
    "df_log['y'] = np.log1p(df_log['precio'])\n",
    "df_log['ds'] = df_log['fecha_hora']\n",
    "df_prophet_log = df_log[['ds', 'y']]\n",
    "\n",
    "modelo_log = Prophet()\n",
    "modelo_log.fit(df_prophet_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff4c57",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "## 3. Proyecci√≥n a 1, 3 y 5 a√±os\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "horas_1a = 365 * 24\n",
    "horas_3a = 3 * horas_1a\n",
    "horas_5a = 5 * horas_1a\n",
    "\n",
    "futuro_5a = modelo_log.make_future_dataframe(periods=horas_5a, freq='H')\n",
    "pronostico_5a = modelo_log.predict(futuro_5a)\n",
    "pronostico_5a['yhat_real'] = np.expm1(pronostico_5a['yhat'])\n",
    "\n",
    "# Filtramos para las proyecciones de 1, 3 y 5 a√±os\n",
    "fecha_inicio = df['fecha_hora'].max()\n",
    "\n",
    "pronostico_1a = pronostico_5a[pronostico_5a['ds'] <= fecha_inicio + pd.Timedelta(days=365)]\n",
    "pronostico_3a = pronostico_5a[pronostico_5a['ds'] <= fecha_inicio + pd.Timedelta(days=3*365)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93176b3",
   "metadata": {},
   "source": [
    "# --------------------------\n",
    "# 4. Visualizaci√≥n\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df['fecha_hora'], df['precio'], label='Precio real', linewidth=1)\n",
    "plt.plot(pronostico_1a['ds'], pronostico_1a['yhat_real'], label='Proyecci√≥n 1 a√±o')\n",
    "plt.plot(pronostico_3a['ds'], pronostico_3a['yhat_real'], label='Proyecci√≥n 3 a√±os')\n",
    "plt.plot(pronostico_5a['ds'], pronostico_5a['yhat_real'], label='Proyecci√≥n 5 a√±os')\n",
    "plt.legend()\n",
    "plt.title(\"Proyecci√≥n Anual del Precio (PML)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Precio\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc05df",
   "metadata": {},
   "source": [
    "# --------------------------\n",
    "# 6. M√©tricas de error solo sobre el hist√≥rico\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fe7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pronostico_5a[['ds', 'yhat_real']].rename(columns={'ds': 'fecha_hora', 'yhat_real': 'precio_predicho'})\n",
    "df_real = df[['fecha_hora', 'precio']]\n",
    "\n",
    "comparacion = pd.merge(df_real, df_pred, on='fecha_hora', how='inner')\n",
    "mae = mean_absolute_error(comparacion['precio'], comparacion['precio_predicho'])\n",
    "rmse = np.sqrt(mean_squared_error(comparacion['precio'], comparacion['precio_predicho']))\n",
    "mape = np.mean(np.abs((comparacion['precio'] - comparacion['precio_predicho']) / comparacion['precio'])) * 100\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4953ef",
   "metadata": {},
   "source": [
    "# --------------------------\n",
    "# 7. Exportar para Power BI\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc643f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronostico_exportar = pronostico_5a[['ds', 'yhat_real']].rename(columns={\n",
    "    'ds': 'fecha_hora',\n",
    "    'yalse)hat_real': 'precio_proyectado'\n",
    "})\n",
    "\n",
    "# Exportar a CSV\n",
    "pronostico_exportar.to_csv('proyeccion_anual_pml.csv', index=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
